{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Titanic: Machine Learning From Disaster\nIn this notebook I'm going to expand on my previous attempt that used scikit-learn random forests and try to use pytorch as the learning framework this time.\n\nStep 1: Load the modules and see what versions we have installed."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\nimport torch\nimport pandas as pd\nimport numpy as np\nprint(f'matplotlib: {matplotlib.__version__}')\nprint(f'pytorch   : {torch.__version__}')\nprint(f'pandas    : {pd.__version__}')\nprint(f'numpy     : {np.__version__}')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## Format the data\nNext step is to format the data so that we can use it to actually train and test our data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\ndf = pd.read_csv(\"../input/titanic/train.csv\")\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The formatting that we will apply includes the following:\n* **One-hot encode**: 'Sex', 'Embarked'\n* **Remove**: 'Name', 'Ticket', 'Cabin'\n* **Fill *null* values** with the mean of the associated column."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\ndef format_feats(in_feats):\n    x = in_feats.values #returns a numpy array\n    min_max_scaler = preprocessing.MinMaxScaler()\n    x_scaled = min_max_scaler.fit_transform(x)\n    return pd.DataFrame(x_scaled, columns=in_feats.columns)\n\n# Apply some data formatting\ndef format_data(data):\n    # One-hot encode 'Embarked' column\n    data = pd.get_dummies(data, columns=['Sex','Embarked'])\n    # Drop columns that require additional processing\n    data = data.drop(['Name','Ticket','Cabin'], axis=1)\n    # Fill null values with the mean of the column\n    data.fillna(data.mean(), inplace=True)\n    if 'Survived' in data.columns:\n        data_y = data['Survived']\n        data_x = data.drop(['Survived'], axis=1)\n        data_x = format_feats(data_x)\n        return data_x, data_y\n    else:\n        return format_feats(data)\n\n# This should split the data into our features and our labels\nfeats, labels = format_data(df)\nfeats.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split the data into training and testing samples\n# The training sample should consist of ~80% of our data\nmask  = np.random.rand(len(feats)) < 0.8\ntrain_X = feats[mask]\ntrain_y = labels[mask]\ntest_X  = feats[~mask]\ntest_y  = labels[~mask]\n\n# Look at the training sample\ntrain_X.describe()\nprint(train_X.describe(), test_y.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Building the model\nNow we need to build a model that is capable of being trained and generating predictions. For this attempt I will be using PyTorch.\n\nNote that we will create a function for generating our model from a list of nodes per layer. This will help us to more easily tune these parameters as we search for the best model."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format the data into PyTorch tensors\ntrn_X = torch.Tensor(train_X.to_numpy())\ntrn_y = torch.Tensor(train_y.to_numpy()).type(torch.LongTensor)\ntst_X = torch.Tensor(test_X.to_numpy())\ntst_y = torch.Tensor(test_y.to_numpy()).type(torch.LongTensor)\n\n# Get the number of inputs\ndrpout = 0.2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate the model\nfrom torch import nn\n\n# Set Dropout rate\ndrpout = 0.1\n# Define number of inputs\ninputs = len(trn_X[0])\n\n# Method for initializing weights and biases\ndef set_weight_bias(layer):\n    layer.bias.data.fill_(0)\n    layer.weight.data.normal_(std=0.01)\n\n# Create a function for model construction\n# This will help \ndef model_construct(inputs, n=[16], outputs=2,\n                    activ=nn.ReLU):\n    # Add the outputs to the list of nodes\n    n.append(outputs)\n    \n    # Input layer\n    layers = []\n    layers.append(nn.Linear(inputs, n[0]))\n    set_weight_bias(layers[-1])\n    layers.append( nn.Dropout(p=drpout) )\n    layers.append(activ())\n    \n    # Loop over the hidden layers\n    for i in range(len(n)-1):\n        layers.append(nn.Linear(n[i], n[i+1]))\n        set_weight_bias(layers[-1])\n        layers.append( nn.Dropout(p=drpout) )\n        layers.append(activ())\n        \n    # Remove the last dropout layer\n    layers.pop()\n    # Change final activation function\n    #layers[-1] = nn.Softmax(dim=1)\n    \n    # Put it all together\n    return nn.Sequential(*layers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And for training/testing the model..."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Write another function for training and testing the model\nfrom torch import optim\nfrom sklearn.utils import shuffle\nfrom torch.autograd import Variable\n\ndef train_model(model, epochs=5, verbose=False):\n    \n    # Setup\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.01)\n    \n    # Loop over the epochs\n    train_losses, test_losses = [0]*epochs, [0]*epochs\n    for e in range(epochs):\n        \n        # Iterate the model, note we are passing in the\n        # entire training set as a single batch\n        optimizer.zero_grad()\n        ps = model(trn_X)\n        loss = criterion(ps, trn_y)\n        loss.backward()\n        optimizer.step()\n        train_losses[e] = loss.item()\n\n        # Compute the test stats\n        with torch.no_grad():\n            # Turn on all the nodes\n            model.eval()\n            \n            # Comput test loss\n            ps = model(tst_X)\n            loss = criterion(ps, tst_y)\n            test_losses[e] = loss.item()\n            \n            # Compute accuracy\n            top_p, top_class = ps.topk(1, dim=1)\n            equals = (top_class == tst_y.view(*top_class.shape))\n            accuracy = torch.mean(equals.type(torch.FloatTensor))\n            \n        model.train()\n        \n    # Print the final information\n    print(f'   Accuracy  : {100*accuracy.item():0.2f}%')\n    print(f'   Train loss: {train_losses[-1]}')\n    print(f'   Test loss : {test_losses[-1]}')\n        \n    # Plot the results\n    plt.plot(train_losses, label='train')\n    plt.plot(test_losses, label='test')\n    plt.legend();\n    return","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Give it a try\nprint(\"Test 1:\")\nmodel = model_construct(inputs, n=[256])\nprint(model)\ntrain_model(model, epochs=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test 2:\")\nmodel = model_construct(inputs, n=[256, 64])\nprint(model)\ntrain_model(model, epochs=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test 3:\")\nmodel = model_construct(inputs, n=[16])\nprint(model)\ntrain_model(model, epochs=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, I guess simple wins the day, so we'll go with the 16 node, single hidden layer model.\n\nThe next thing to do is re-train the model using the full training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Assign the training data to the full training set\ntrn_X = torch.Tensor(feats.to_numpy())\ntrn_y = torch.Tensor(labels.to_numpy()).type(torch.LongTensor)\n\n# Construct and fit the model\nmodel = model_construct(inputs, n=[16])\ntrain_model(model, epochs=10000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit the Result\nNow generate the test results and save them to a file."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load and process the testing data\ntest_df    = pd.read_csv(\"../input/titanic/test.csv\")\ntest_feats = format_data(test_df)\ntest_feats = torch.Tensor(test_feats.to_numpy())\n\n# Compute the results\nresults          = model(test_feats)\ntop_p, top_class = results.topk(1, dim=1)\n\n# Load it all into a dataframe\nsubmission_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], \n                              'Survived'   : top_class.view(-1).numpy()})\nsubmission_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}